{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_b8M907yIDn"
      },
      "outputs": [],
      "source": [
        "#Problem Statement\n",
        "\"\"\"\n",
        "*Sentiment Analysis of Movie Trailer Comments using NLP\n",
        "\n",
        "Conducted a comprehensive sentiment analysis of YouTube comments for a movie trailer as an AI Service Provider, quantifying positive and negative reactions to predict the trailer's potential box office performance. The analysis will:\n",
        "\n",
        "- Classify comment sentiments(positive or negative)\n",
        "- Generate an overall sentiment score\n",
        "- Provide insights into audience reception\n",
        "- Assess the trailer's market appeal\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oed-pm28C8cH"
      },
      "outputs": [],
      "source": [
        "#Tools used in this project:\n",
        "\"\"\"\n",
        "PyTorch - torch\n",
        "HuggingFace - transformers\n",
        "NLTK - nltk\n",
        "VADER - sentiment.vader\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4_mB6gzeuJP"
      },
      "outputs": [],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGIeUEKXgaAP"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yjx65aCzge34"
      },
      "outputs": [],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAfydmKMgkGk"
      },
      "outputs": [],
      "source": [
        "!pip install vaderSentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EH-ciS9phG0p"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0YSYsc6hiHY"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zP0v2ltDi7YF"
      },
      "outputs": [],
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "stop_words = stop_words = set(stopwords.words('english'))\n",
        "classifier = pipeline(\"sentiment-analysis\", model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcXVwXdhj4F6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# Upload the Excel file if it's not already present\n",
        "import os\n",
        "file_path = '/content/SnowWhite Comments YT.xlsx'\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "  uploaded = files.upload()\n",
        "  if 'SnowWhite Comments YT.xlsx' not in uploaded:\n",
        "    print(\"Error: 'SnowWhite Comments YT.xlsx' was not uploaded. Please ensure you upload the correct file.\")\n",
        "  else:\n",
        "    print(\"File 'SnowWhite Comments YT.xlsx' uploaded successfully.\")\n",
        "\n",
        "df = pd.read_excel(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKgS2FsRfObT"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmYsWQR0kAal"
      },
      "outputs": [],
      "source": [
        "comments = []\n",
        "comments = df['Comments'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLlDLDcckOQq"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(raw_comment):\n",
        "  tokenized_comment = word_tokenize(raw_comment)\n",
        "  processed_comment = [ word for word in tokenized_comment if word.lower() not in stop_words]\n",
        "  return ' '.join(processed_comment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvNO8k0VkYBk"
      },
      "outputs": [],
      "source": [
        "def get_comment_sentiment_details(raw_comment):\n",
        "  processed_comment = remove_stopwords(raw_comment)\n",
        "\n",
        "  words = processed_comment.split()\n",
        "  positive_words = \"\"\n",
        "  negative_words = \"\"\n",
        "  comment_sentiment = \"\" #Either positive or negative\n",
        "\n",
        "  sentence_score_temp = sia.polarity_scores(processed_comment)\n",
        "\n",
        "  abs_sentence_score = abs(sentence_score_temp['compound']) #absolute value of -3.4 = 3.4\n",
        "  sentiment_label = classifier( processed_comment)\n",
        "  comment_sentiment = sentiment_label[0]['label']\n",
        "\n",
        "  if abs_sentence_score == 0 :\n",
        "    comment_sentiment = \"NEUTRAL\"\n",
        "\n",
        "  if comment_sentiment == \"NEGATIVE\":\n",
        "    sentence_score = abs_sentence_score * -1\n",
        "    for word in words:\n",
        "      word_sentiment = sia.polarity_scores(word)\n",
        "      if word_sentiment ['compound'] < 0:\n",
        "        negative_words += word + \"\"\n",
        "\n",
        "  elif comment_sentiment == \"POSITIVE\":\n",
        "    sentence_score = abs_sentence_score\n",
        "    for word in words:\n",
        "      word_sentiment = sia.polarity_scores(word)\n",
        "      if word_sentiment['compound'] > 0:\n",
        "        positive_words += word + \" \"\n",
        "  else:\n",
        "    sentence_score = abs_sentence_score\n",
        "\n",
        "  return positive_words, negative_words, sentence_score, comment_sentiment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLDrqhA5sVfw"
      },
      "outputs": [],
      "source": [
        "positive_words = \"\"\n",
        "negative_words = \"\"\n",
        "\n",
        "pos_values_list = []\n",
        "neg_values_list = []\n",
        "avg_pos_score = 0\n",
        "avg_neg_score = 0\n",
        "neu_count = 0\n",
        "\n",
        "for comment in comments:\n",
        "  pw, nw, ss, cs = get_comment_sentiment_details(comment)\n",
        "  positive_words += pw + \" \" #storing pw from each comment into our central positive words\n",
        "  negative_words += nw + \" \"\n",
        "\n",
        "  if cs == \"NEGATIVE\":\n",
        "    neg_values_list.append(ss)\n",
        "  elif cs == \"POSITIVE\":\n",
        "    pos_values_list.append(ss)\n",
        "  else:\n",
        "    neu_count += 1\n",
        "\n",
        "  try:\n",
        "    avg_pos_score = sum(pos_values_list) / len(pos_values_list)\n",
        "    avg_neg_score = sum(neg_values_list) / len(neg_values_list)\n",
        "  except ZeroDivisionError:\n",
        "    if len(pos_values_list) == 0 or len(neg_values_list) == 0:\n",
        "      avg_pos_score = 0\n",
        "      avg_neg_score = 0\n",
        "\n",
        "  final_score = (avg_pos_score + avg_neg_score) / (len(pos_values_list) + len(neg_values_list))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KD8MrrQZ45yP"
      },
      "outputs": [],
      "source": [
        "print(final_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuseD9K45Ksx"
      },
      "outputs": [],
      "source": [
        "positive_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyLajjR85RDD"
      },
      "outputs": [],
      "source": [
        "negative_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOboRYlA5bs9"
      },
      "outputs": [],
      "source": [
        "avg_pos_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0p0GVuR5eCE"
      },
      "outputs": [],
      "source": [
        "avg_neg_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "el0GB09p5YgS"
      },
      "outputs": [],
      "source": [
        "!pip install wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qYJY0F85t2V"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"positives\")\n",
        "\n",
        "wordcloud_positive = WordCloud(width = 800 ,height = 400, background_color = 'purple').generate(positive_words)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.imshow(wordcloud_positive, interpolation = 'bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEOzwGqV-Dfh"
      },
      "outputs": [],
      "source": [
        "print(\"negatives\")\n",
        "\n",
        "wordcloud_negative = WordCloud(width = 800, height = 400, background_color = 'red').generate(negative_words)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.imshow(wordcloud_negative, interpolation = 'bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}